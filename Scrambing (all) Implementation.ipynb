{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b462e49-1b18-48c8-a404-915634203c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read file\n",
    "final_training_set = pd.read_csv(\"MDM2_trainset_scaffold_outer.csv\")\n",
    "\n",
    "# Create a new trainset1 DataFrame\n",
    "final_training_set = final_training_set.copy()\n",
    "\n",
    "# Randomly shuffle the 'pChEMBL_gt6' column\n",
    "final_training_set['pChEMBL_gt6'] = final_training_set['pChEMBL_gt6'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, selection_pool = train_test_split(\n",
    "    final_training_set, \n",
    "    test_size=0.9,  # 90% for selection pool\n",
    "    stratify=final_training_set['pChEMBL_gt6'],  # Stratify based on the 'pChEMBL_gt6' column\n",
    "    random_state=20  # Ensure reproducibility\n",
    ")\n",
    "\n",
    "print(f\"Training Subset size: {len(train_set)}, Selection Pool size: {len(selection_pool)}\")\n",
    "\n",
    "# Randomly sample 50% of train_set\n",
    "train_subset, _ = train_test_split(\n",
    "    train_set, \n",
    "    test_size=0.5,  # Drop 50%\n",
    "    stratify=train_set['pChEMBL_gt6'],  # Maintain class distribution\n",
    "    random_state=42  # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# Randomly sample 50% of selection_pool\n",
    "selection_pool_subset, _ = train_test_split(\n",
    "    selection_pool, \n",
    "    test_size=0.5,  # Drop 50%\n",
    "    stratify=selection_pool['pChEMBL_gt6'],  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train Subset size: {len(train_subset)}, Selection Pool Subset size: {len(selection_pool_subset)}\")\n",
    "\n",
    "# Save the subsets\n",
    "train_subset.to_csv(\"MDM2_scaffold_train_set_scrambling_train_20rd.csv\", index=False)\n",
    "selection_pool_subset.to_csv(\"MDM2_scaffold_selection_pool_scrambling_train_20rd.csv\", index=False)\n",
    "\n",
    "# Active Learning Code Starts Here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, average_precision_score, precision_recall_curve, auc, balanced_accuracy_score\n",
    ")\n",
    "from joblib import Parallel, delayed  # Parallel computation\n",
    "from scipy.stats import entropy  # For entropy calculation\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define directory to save results\n",
    "save_dir = \"C:\\\\Users\\\\jen\\\\Proteins\\\\MDM2\\\\Scaffold outersplit\\\\Results\\\\MDM2_Scrambling_train_scaffold\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Set random seed\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# **Parallelized SMILES -> ECFP conversion**\n",
    "def smiles_to_ecfp_counts(smiles_list, radius=3, nBits=2048):\n",
    "    def compute_fingerprint(smiles):\n",
    "        mol = AllChem.MolFromSmiles(smiles)\n",
    "        if mol:\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits)\n",
    "            arr = np.zeros((nBits,), dtype=np.uint8)\n",
    "            DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "            return arr\n",
    "        return np.zeros(nBits, dtype=np.uint8)\n",
    "    \n",
    "    fingerprints = Parallel(n_jobs=-1)(delayed(compute_fingerprint)(smiles) for smiles in smiles_list)\n",
    "    return np.array(fingerprints)\n",
    "\n",
    "# Train SVM model\n",
    "def train_svc(train_features, train_labels):\n",
    "    model = SVC(\n",
    "        C=14.760052670334735, \n",
    "        gamma=0.011087183655158359, \n",
    "        class_weight=\"balanced\", \n",
    "        probability=True, \n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(train_features, train_labels)\n",
    "    return model\n",
    "\n",
    "# Predict probabilities\n",
    "def predict_with_uncertainty(model, test_features):\n",
    "    return model.predict_proba(test_features)\n",
    "\n",
    "# Calculate entropy-based uncertainty\n",
    "def compute_entropy_uncertainty(probabilities):\n",
    "    return entropy(probabilities.T, axis=0)\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(predictions, expected):\n",
    "    predicted_labels = (predictions >= 0.5).astype(int)\n",
    "    accuracy = accuracy_score(expected, predicted_labels)\n",
    "    balanced_acc = balanced_accuracy_score(expected, predicted_labels)\n",
    "    average_precision = average_precision_score(expected, predictions)\n",
    "    precision, recall, _ = precision_recall_curve(expected, predictions)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    return accuracy, balanced_acc, average_precision, auc_pr\n",
    "\n",
    "# Active Learning main loop using VeenaBers uncertainty (entropy-based)\n",
    "def active_learning_loop(selection_pool, train_set, test_set, max_iterations=10, molecules_to_select=400):\n",
    "    print(\"Training initial SVC model...\")\n",
    "\n",
    "    # **Cache features for training data**\n",
    "    train_set[\"features\"] = list(smiles_to_ecfp_counts(train_set[\"canonical_smiles\"].tolist()))\n",
    "    train_features = np.vstack(train_set[\"features\"].values)\n",
    "    train_labels = train_set[\"pChEMBL_gt6\"].values\n",
    "\n",
    "    model = train_svc(train_features, train_labels)\n",
    "\n",
    "    # **Cache test data**\n",
    "    test_features = smiles_to_ecfp_counts(test_set[\"canonical_smiles\"].tolist())\n",
    "    test_labels = test_set[\"pChEMBL_gt6\"].values\n",
    "\n",
    "    test_probabilities = predict_with_uncertainty(model, test_features)\n",
    "    test_predictions = test_probabilities[:, 1]\n",
    "    accuracy, balanced_acc, avg_precision, auc_pr = evaluate_model(test_predictions, test_labels)\n",
    "\n",
    "    results = [{\n",
    "        \"iteration\": 0, \n",
    "        \"accuracy\": accuracy, \n",
    "        \"balanced_accuracy\": balanced_acc,  \n",
    "        \"average_precision\": avg_precision, \n",
    "        \"auc_pr\": auc_pr\n",
    "    }]\n",
    "\n",
    "    print(f\"Initial Model Results: Accuracy={accuracy:.4f}, Balanced Accuracy={balanced_acc:.4f}, AP={avg_precision:.4f}, AUC-PR={auc_pr:.4f}\")\n",
    "\n",
    "    # **Cache features for selection pool**\n",
    "    selection_pool[\"features\"] = list(smiles_to_ecfp_counts(selection_pool[\"canonical_smiles\"].tolist()))\n",
    "\n",
    "    for iteration in range(1, max_iterations + 1):\n",
    "        print(f\"Iteration {iteration}: Selection Pool Size = {len(selection_pool)}\")\n",
    "\n",
    "        selection_features = np.vstack(selection_pool[\"features\"].values)\n",
    "        selection_probabilities = predict_with_uncertainty(model, selection_features)\n",
    "\n",
    "        # **Calculate entropy-based uncertainty**\n",
    "        uncertainties = compute_entropy_uncertainty(selection_probabilities)\n",
    "        selection_pool[\"uncertainty\"] = uncertainties\n",
    "\n",
    "        # **Select molecules with highest entropy (most uncertain)**\n",
    "        selected_molecules = selection_pool.nlargest(molecules_to_select, \"uncertainty\")\n",
    "\n",
    "        # **Update training set**\n",
    "        train_set = pd.concat([train_set, selected_molecules], ignore_index=True)\n",
    "        selection_pool.drop(index=selected_molecules.index, inplace=True)\n",
    "\n",
    "        print(f\"Iteration {iteration}: Train set size = {len(train_set)}\")\n",
    "\n",
    "        # **Retrain model**\n",
    "        train_features = np.vstack(train_set[\"features\"].values)\n",
    "        train_labels = train_set[\"pChEMBL_gt6\"].values\n",
    "        model = train_svc(train_features, train_labels)\n",
    "\n",
    "        test_probabilities = predict_with_uncertainty(model, test_features)\n",
    "        test_predictions = test_probabilities[:, 1]\n",
    "        accuracy, balanced_acc, avg_precision, auc_pr = evaluate_model(test_predictions, test_labels)\n",
    "\n",
    "        results.append({\n",
    "            \"iteration\": iteration, \n",
    "            \"accuracy\": accuracy, \n",
    "            \"balanced_accuracy\": balanced_acc,  \n",
    "            \"average_precision\": avg_precision, \n",
    "            \"auc_pr\": auc_pr\n",
    "        })\n",
    "\n",
    "        print(f\"Iteration {iteration} Results: Accuracy={accuracy:.4f}, Balanced Accuracy={balanced_acc:.4f}, AP={avg_precision:.4f}, AUC-PR={auc_pr:.4f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# **Initialize data**\n",
    "train_set = pd.read_csv(\"MDM2_scaffold_train_set_scrambling_train_20rd.csv\")\n",
    "selection_pool = pd.read_csv(\"MDM2_scaffold_selection_pool_scrambling_train_20rd.csv\")\n",
    "test_set = pd.read_csv(\"./Data/MDM2_scaffold_test_set_20.csv\")\n",
    "\n",
    "# **Start Active Learning**\n",
    "molecules_to_select = 400\n",
    "max_iterations = 10\n",
    "results = active_learning_loop(selection_pool, train_set, test_set, max_iterations, molecules_to_select)\n",
    "\n",
    "# **Save results**\n",
    "save_path = os.path.join(save_dir, \"MDM2_scrambling_train_scaffold_R1.csv\")\n",
    "pd.DataFrame(results).to_csv(save_path, index=False)\n",
    "print(f\"Results saved to {save_path}\")\n",
    "print(\"Active Learning Process Completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
